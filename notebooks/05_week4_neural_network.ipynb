{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-08T15:45:43.620749Z",
     "start_time": "2026-01-08T15:45:43.618587Z"
    }
   },
   "cell_type": "markdown",
   "source": "# Setup",
   "id": "205bf1a58fd970f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T16:30:06.195331Z",
     "start_time": "2026-01-08T16:30:06.190849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, ConstantKernel\n",
    "from scipy.optimize import minimize\n",
    "from utils import load_data\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(44) # New seed for Week 4\n",
    "\n",
    "print(\"Ready for Neural Surrogate Optimization\")"
   ],
   "id": "d80fdca4731a981f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready for Neural Surrogate Optimization\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Neural Gradient Ascent Strategy",
   "id": "f7cceb9c999fb83c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T16:33:12.291635Z",
     "start_time": "2026-01-08T16:33:12.281413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def suggest_next_point_neural_gradient(func_id, X_train, y_train):\n",
    "    print(f\"--- Optimizing Function {func_id} ---\")\n",
    "\n",
    "    # 1. Preprocessing (Critical for NNs)\n",
    "    # Inputs must be scaled (standard scaling usually better for gradients than MinMax)\n",
    "    scaler_x = StandardScaler()\n",
    "    X_scaled = scaler_x.fit_transform(X_train)\n",
    "\n",
    "    scaler_y = StandardScaler()\n",
    "    y_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # 2. Train Surrogate Models\n",
    "\n",
    "    # Model A: Neural Network (The \"Gradient Climber\")\n",
    "    # Using L-BFGS because it works much better on small datasets than Adam\n",
    "    # Tanh activation gives smooth gradients (unlike ReLU which has dead zones)\n",
    "    nn_model = MLPRegressor(hidden_layer_sizes=(32, 32),\n",
    "                            activation='tanh',\n",
    "                            solver='lbfgs',\n",
    "                            max_iter=2000,\n",
    "                            random_state=42)\n",
    "    nn_model.fit(X_scaled, y_scaled)\n",
    "\n",
    "    # Model B: Gaussian Process (The \"Safety Net\")\n",
    "    kernel = ConstantKernel(1.0) * Matern(length_scale=1.0, nu=2.5) + WhiteKernel(noise_level=0.1)\n",
    "    gp_model = GaussianProcessRegressor(kernel=kernel, normalize_y=False)\n",
    "    gp_model.fit(X_scaled, y_scaled)\n",
    "\n",
    "    # 3. Define the Acquisition / Objective Function\n",
    "    # We want to find x that maximizes (NN_pred + GP_pred)\n",
    "    # Since scipy.minimize minimizes, we return the negative sum.\n",
    "\n",
    "    def objective_function(x):\n",
    "        # x comes in as 1D array. Reshape for sklearn.\n",
    "        x_reshaped = x.reshape(1, -1)\n",
    "\n",
    "        # Predict with NN\n",
    "        nn_pred = nn_model.predict(x_reshaped)\n",
    "\n",
    "        # Predict with GP\n",
    "        gp_pred = gp_model.predict(x_reshaped)\n",
    "\n",
    "        # Weighted Ensemble:\n",
    "        # Func 8 (High dim) -> Trust GP more (NN overfits easily in 8D with 13 points)\n",
    "        # Func 2, 5 (Strong signals) -> Trust NN gradients more\n",
    "        if func_id == 8:\n",
    "            combined = 0.3 * nn_pred + 0.7 * gp_pred\n",
    "        else:\n",
    "            combined = 0.6 * nn_pred + 0.4 * gp_pred\n",
    "\n",
    "        return -combined[0] # Negative because we want to MAXIMIZE\n",
    "\n",
    "    # 4. Gradient-Based Optimization (The \"Steering\")\n",
    "    # Instead of random sampling, we start from the BEST point we've seen so far\n",
    "    # and \"climb the hill\" using the gradients of our surrogate models.\n",
    "\n",
    "    best_idx = np.argmax(y_train)\n",
    "    x_start_original = X_train[best_idx]\n",
    "    x_start_scaled = scaler_x.transform(x_start_original.reshape(1, -1)).flatten()\n",
    "\n",
    "    # Bounds in scaled space\n",
    "    # We need to approximate bounds since scaler shifts them.\n",
    "    # Let's just run optimization and clip later to be safe, or use approximate bounds.\n",
    "    # L-BFGS-B allows bounds.\n",
    "\n",
    "    # Run Optimizer\n",
    "    res = minimize(fun=objective_function,\n",
    "                   x0=x_start_scaled,\n",
    "                   method='L-BFGS-B',\n",
    "                   options={'maxiter': 100, 'eps': 1e-5})\n",
    "\n",
    "    # 5. Inverse Transform to get real X\n",
    "    x_optimized_scaled = res.x.reshape(1, -1)\n",
    "    next_point = scaler_x.inverse_transform(x_optimized_scaled).flatten()\n",
    "\n",
    "    # Clip to ensure we stay in [0, 1] box\n",
    "    next_point = np.clip(next_point, 0.0, 1.0)\n",
    "\n",
    "    # Exploration Jitter\n",
    "    # If the optimizer got stuck exactly at the start point (gradient is 0), add noise\n",
    "    if np.linalg.norm(next_point - x_start_original) < 1e-6:\n",
    "        print(\"   Gradient stuck, adding exploration jitter.\")\n",
    "        next_point += np.random.normal(0, 0.1, size=next_point.shape)\n",
    "        next_point = np.clip(next_point, 0.0, 1.0)\n",
    "\n",
    "    return next_point"
   ],
   "id": "fd5e1c64b26223e8",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Run and Format",
   "id": "3bb3d2e48af4d980"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T16:37:51.815277Z",
     "start_time": "2026-01-08T16:37:50.184979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "submission_queries = {}\n",
    "print(f\"{'Func':<5} | {'Optimizing...'}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "for func_id in range(1, 9):\n",
    "    X_known, y_known = load_data(func_id)\n",
    "    next_x = suggest_next_point_neural_gradient(func_id, X_known, y_known)\n",
    "    submission_queries[func_id] = next_x\n",
    "\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"FORMATTED SUBMISSION OUTPUT\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "for func_id, x_val in submission_queries.items():\n",
    "    formatted_str = \" - \".join([f\"{val:.6f}\" for val in x_val])\n",
    "    print(f\"function_number: {func_id}: {formatted_str}\")"
   ],
   "id": "374c5398b4e0ce56",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Func  | Optimizing...\n",
      "------------------------------\n",
      "--- Optimizing Function 1 ---\n",
      "--- Optimizing Function 2 ---\n",
      "--- Optimizing Function 3 ---\n",
      "--- Optimizing Function 4 ---\n",
      "--- Optimizing Function 5 ---\n",
      "--- Optimizing Function 6 ---\n",
      "--- Optimizing Function 7 ---\n",
      "--- Optimizing Function 8 ---\n",
      "\n",
      "==============================\n",
      "FORMATTED SUBMISSION OUTPUT\n",
      "==============================\n",
      "function_number: 1: 0.000000-1.000000\n",
      "function_number: 2: 0.770326-1.000000\n",
      "function_number: 3: 0.381485-0.407667-0.447654\n",
      "function_number: 4: 0.400327-0.416657-0.457421-0.423750\n",
      "function_number: 5: 1.000000-1.000000-1.000000-1.000000\n",
      "function_number: 6: 0.286724-0.288061-0.514199-0.662913-0.053490\n",
      "function_number: 7: 0.000000-0.326950-0.413602-0.271175-0.421867-0.538347\n",
      "function_number: 8: 0.000000-0.363803-0.000000-0.330744-0.715120-0.767185-0.190904-0.626834\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
