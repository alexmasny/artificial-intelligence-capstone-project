{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 8: LLM-Informed Optimization\n",
    "\n",
    "## Strategy: The \"LLM-Critic\" Hybrid\n",
    "Module 19 focuses on Generative AI. Since LLMs struggle with precise floating-point math (hallucinations), we adopt a hybrid strategy:\n",
    "1. **Numerical Engine (Primary):** We rely on the `Adaptive AutoML` + `Trust Region` strategy (Week 7) to calculate precise candidates.\n",
    "2. **Prompt Generation (Secondary):** We construct **Few-Shot Chain-of-Thought** prompts from our data. This allows us to conceptually frame the optimization as a sequence prediction task, analyzing token usage and context windows.\n",
    "3. **Objective:** Use the numerical engine for the submission to ensure validity, while analyzing the data structure through the lens of LLM constraints (tokens, temperature) for the reflection."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T14:03:46.956369Z",
     "start_time": "2026-02-05T14:03:42.833453Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, ConstantKernel\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.optimize import minimize\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Ensure we can import from src\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from src.utils import load_data\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(48) # Week 8 Seed\n",
    "\n",
    "print(\"Ready for LLM-Informed Optimization\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready for LLM-Informed Optimization\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T14:03:46.966647Z",
     "start_time": "2026-02-05T14:03:46.960417Z"
    }
   },
   "source": [
    "# --- Helper: Generate Prompt for Reflection Purposes ---\n",
    "def generate_llm_prompt(func_id, X, y):\n",
    "    \"\"\"\n",
    "    Creates a Few-Shot Prompt representing the function history.\n",
    "    Used to analyze token usage and context structure.\n",
    "    \"\"\"\n",
    "    prompt = f\"You are an optimization assistant. Analyze the following {len(y)} experiments for Function {func_id} (Maximize Y).\\n\\n\"\n",
    "    prompt += \"History (Inputs -> Output):\\n\"\n",
    "    \n",
    "    # Sort by Y to show the 'path to success'\n",
    "    sorted_indices = np.argsort(y)\n",
    "    for idx in sorted_indices:\n",
    "        inputs_str = \", \".join([f\"{val:.4f}\" for val in X[idx]])\n",
    "        prompt += f\"Input: [{inputs_str}] -> Output: {y[idx]:.4f}\\n\"\n",
    "    \n",
    "    prompt += \"\\nBased on these examples, identify the trend and suggest the next input vector X to maximize Y.\\n\"\n",
    "    prompt += \"Constraints: All values must be between 0.0 and 1.0.\\n\"\n",
    "    return prompt"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T14:03:46.979995Z",
     "start_time": "2026-02-05T14:03:46.967673Z"
    }
   },
   "source": [
    "# --- Core Strategy: Adaptive AutoML (from Week 7) ---\n",
    "def tune_surrogate_model(X, y):\n",
    "    # Hyperparameter Space\n",
    "    param_dist = {\n",
    "        'hidden_layer_sizes': [(32,), (64,), (32, 32), (64, 32), (128, 64)],\n",
    "        'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "        'activation': ['tanh', 'relu'],\n",
    "    }\n",
    "    mlp = MLPRegressor(solver='lbfgs', max_iter=2000, random_state=42)\n",
    "    # Randomized Search (3-fold CV)\n",
    "    search = RandomizedSearchCV(mlp, param_dist, n_iter=15, cv=3, \n",
    "                                scoring='neg_mean_squared_error', n_jobs=-1, random_state=42)\n",
    "    search.fit(X, y)\n",
    "    return search.best_params_\n",
    "\n",
    "def suggest_next_point_hybrid(func_id, X_train, y_train):\n",
    "    # 1. Generate LLM Prompt (for observation/reflection)\n",
    "    prompt = generate_llm_prompt(func_id, X_train, y_train)\n",
    "    if func_id == 1:\n",
    "        print(f\"--- Generated Prompt for Func {func_id} (Preview) ---\")\n",
    "        print(prompt[:300] + \"...[truncated]...\") \n",
    "        print(f\"Estimated Tokens: {len(prompt.split()) * 1.3:.0f}\")\n",
    "    \n",
    "    print(f\"--- Optimizing Function {func_id} (Adaptive w/ Repulsion) ---\")\n",
    "    \n",
    "    # 2. Preprocessing\n",
    "    scaler_x = StandardScaler()\n",
    "    X_scaled = scaler_x.fit_transform(X_train)\n",
    "    scaler_y = StandardScaler()\n",
    "    y_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    # 3. Tuning & Training\n",
    "    best_params = tune_surrogate_model(X_scaled, y_scaled)\n",
    "    nn_ensemble = []\n",
    "    for seed in [42, 101, 999]:\n",
    "        model = MLPRegressor(solver='lbfgs', max_iter=3000, random_state=seed, **best_params)\n",
    "        model.fit(X_scaled, y_scaled)\n",
    "        nn_ensemble.append(model)\n",
    "        \n",
    "    kernel = ConstantKernel(1.0) * Matern(length_scale=1.0, nu=2.5) + WhiteKernel(noise_level=0.1)\n",
    "    gp_model = GaussianProcessRegressor(kernel=kernel, normalize_y=False)\n",
    "    gp_model.fit(X_scaled, y_scaled)\n",
    "    \n",
    "    # 4. Objective with Repulsion & UCB (The \"Fix\" from Week 7)\n",
    "    best_idx = np.argmax(y_train)\n",
    "    x_start_original = X_train[best_idx]\n",
    "    x_start_scaled = scaler_x.transform(x_start_original.reshape(1, -1)).flatten()\n",
    "    \n",
    "    def objective_function(x):\n",
    "        x_reshaped = x.reshape(1, -1)\n",
    "        nn_preds = [m.predict(x_reshaped)[0] for m in nn_ensemble]\n",
    "        # Ensemble Stats\n",
    "        avg_nn = np.mean(nn_preds)\n",
    "        std_nn = np.std(nn_preds)\n",
    "        gp_pred, gp_std = gp_model.predict(x_reshaped, return_std=True)\n",
    "        \n",
    "        # Combined UCB\n",
    "        comb_mean = 0.6 * avg_nn + 0.4 * gp_pred[0]\n",
    "        comb_std = 0.6 * std_nn + 0.4 * gp_std[0]\n",
    "        ucb = comb_mean + 1.96 * comb_std\n",
    "        \n",
    "        # Repulsion Penalty\n",
    "        dist_sq = np.sum((x_reshaped - x_start_scaled)**2)\n",
    "        penalty = 10.0 * np.exp(-dist_sq / (2 * 0.1**2))\n",
    "        \n",
    "        return -ucb + penalty\n",
    "\n",
    "    # 5. Trust Region Optimization\n",
    "    radius = 0.2\n",
    "    bounds_scaled = []\n",
    "    for i in range(X_train.shape[1]):\n",
    "        mean, scale = scaler_x.mean_[i], scaler_x.scale_[i]\n",
    "        curr_val = x_start_original[i]\n",
    "        lower = (max(0.0, curr_val - radius) - mean) / scale\n",
    "        upper = (min(1.0, curr_val + radius) - mean) / scale\n",
    "        bounds_scaled.append((lower, upper))\n",
    "    \n",
    "    # Perturbed start\n",
    "    x_init = x_start_scaled + np.random.uniform(-0.1, 0.1, size=x_start_scaled.shape)\n",
    "    \n",
    "    res = minimize(fun=objective_function, x0=x_init, method='L-BFGS-B', \n",
    "                   bounds=bounds_scaled, options={'maxiter': 100})\n",
    "    \n",
    "    return np.clip(scaler_x.inverse_transform(res.x.reshape(1, -1)).flatten(), 0.0, 1.0)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T21:19:18.412850Z",
     "start_time": "2026-02-05T21:18:32.917316Z"
    }
   },
   "source": [
    "submission_queries = {}\n",
    "print(f\"{'Func':<5} | {'Optimizing...'}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "for func_id in range(1, 9):\n",
    "    # Ensure you have updated data to 17 points (10+7) before running\n",
    "    X_known, y_known = load_data(func_id)\n",
    "    next_x = suggest_next_point_hybrid(func_id, X_known, y_known)\n",
    "    submission_queries[func_id] = next_x\n",
    "\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"FORMATTED SUBMISSION OUTPUT\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "for func_id, x_val in submission_queries.items():\n",
    "    formatted_str = \"-\".join([f\"{val:.6f}\" for val in x_val])\n",
    "    print(f\"function_number: {func_id}: {formatted_str}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "FORMATTED SUBMISSION OUTPUT\n",
      "==============================\n",
      "function_number: 1: 0.931024-0.717283\n",
      "function_number: 2: 0.511417-0.727013\n",
      "function_number: 3: 0.309052-0.477563-0.466159\n",
      "function_number: 4: 0.413347-0.464374-0.376904-0.384008\n",
      "function_number: 5: 1.000000-1.000000-0.800000-1.000000\n",
      "function_number: 6: 0.387153-0.355004-0.525003-0.783371-0.145920\n",
      "function_number: 7: 0.000000-0.356489-0.455144-0.242287-0.255521-0.756803\n",
      "function_number: 8: 0.000000-0.000000-0.187751-0.163048-0.674043-0.602089-0.000000-0.746610\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "What was sent\n",
    "\n",
    "```\n",
    "function_number: 1: 0.888647-0.933000\n",
    "function_number: 2: 0.511417-0.727013\n",
    "function number: 3: 0.554344-0.479092-0.490840\n",
    "function_number: 4: 0.486697-0.324952-0.448014-0.369212\n",
    "function_number: 5: 0.901030-1.000000-1.000000-1.000000\n",
    "function_number: 6: 0.341863-0.412545-0.596785-0.795638-0.000000\n",
    "function_number: 7: 0.000000-0.391975-0.550956-0.330957-0.483694-0.851496\n",
    "function_number: 8: 0.000000-0.384962-0.000000-0.013207-0.274043-0.239238-0.000000-0.746610\n",
    "```"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
