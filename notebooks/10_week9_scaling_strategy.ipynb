{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 9: Scaling Laws & Emergent Behaviors\n",
    "\n",
    "## Strategy: Scaling the Ensemble\n",
    "Module 20 focuses on Scaling Laws. In BBO with sparse data (18 points), we cannot scale data, but we can scale **Model Capacity** and **Compute**.\n",
    "1. **Massive Ensembling:** We scale from 3 models to **20 Neural Networks** (Bagging). According to scaling laws, this should linearly reduce the variance of our uncertainty estimate.\n",
    "2. **Emergent Robustness:** We look for emergent stability in high-dimensional functions (Func 8) where smaller ensembles failed to converge.\n",
    "3. **Repulsion & Trust Regions:** We maintain the Week 7 fixes to prevent boundary saturation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T15:08:34.439102Z",
     "start_time": "2026-02-12T15:08:30.233958Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, ConstantKernel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.optimize import minimize\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Ensure we can import from src\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from src.utils import load_data\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(49) # Week 9 Seed\n",
    "\n",
    "print(\"Ready for Scaled Optimization\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready for Scaled Optimization\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T15:08:34.453073Z",
     "start_time": "2026-02-12T15:08:34.442416Z"
    }
   },
   "source": [
    "def suggest_next_point_scaled(func_id, X_train, y_train):\n",
    "    print(f\"--- Optimizing Function {func_id} (Scaled Ensemble N=20) ---\")\n",
    "    \n",
    "    # 1. Preprocessing\n",
    "    scaler_x = StandardScaler()\n",
    "    X_scaled = scaler_x.fit_transform(X_train)\n",
    "    scaler_y = StandardScaler()\n",
    "    y_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    # 2. Define Base Model (Architecture from Week 7 Tuning)\n",
    "    # We use a robust architecture found previously to save compute time during bagging\n",
    "    if func_id in [7, 8]:\n",
    "        hidden_layers = (128, 64)\n",
    "        alpha = 0.01\n",
    "    else:\n",
    "        hidden_layers = (64, 32)\n",
    "        alpha = 0.01\n",
    "        \n",
    "    base_mlp = MLPRegressor(hidden_layer_sizes=hidden_layers, alpha=alpha, \n",
    "                            activation='tanh', solver='lbfgs', max_iter=2000)\n",
    "    \n",
    "    # 3. SCALING: Train 20 models (Bagging)\n",
    "    # This mimics \"scaling up\" compute to improve robustness\n",
    "    regr = BaggingRegressor(estimator=base_mlp, n_estimators=20, \n",
    "                            random_state=42, n_jobs=-1)\n",
    "    regr.fit(X_scaled, y_scaled)\n",
    "    \n",
    "    # GP Anchor (Fixed)\n",
    "    kernel = ConstantKernel(1.0) * Matern(length_scale=1.0, nu=2.5) + WhiteKernel(noise_level=0.1)\n",
    "    gp_model = GaussianProcessRegressor(kernel=kernel, normalize_y=False)\n",
    "    gp_model.fit(X_scaled, y_scaled)\n",
    "    \n",
    "    # 4. Objective Function\n",
    "    best_idx = np.argmax(y_train)\n",
    "    x_start_original = X_train[best_idx]\n",
    "    x_start_scaled = scaler_x.transform(x_start_original.reshape(1, -1)).flatten()\n",
    "    \n",
    "    def objective_function(x):\n",
    "        x_reshaped = x.reshape(1, -1)\n",
    "        \n",
    "        # Get predictions from all 20 estimators\n",
    "        # BaggingRegressor doesn't expose individual predictions easily in one call,\n",
    "        # so we iterate. This is computationally expensive but fits the \"Scaling\" theme.\n",
    "        nn_preds = np.array([est.predict(x_reshaped)[0] for est in regr.estimators_])\n",
    "        \n",
    "        avg_nn = np.mean(nn_preds)\n",
    "        std_nn = np.std(nn_preds)\n",
    "        \n",
    "        gp_pred, gp_std = gp_model.predict(x_reshaped, return_std=True)\n",
    "        gp_pred = gp_pred[0]\n",
    "        gp_std = gp_std[0]\n",
    "        \n",
    "        # Combined UCB\n",
    "        comb_mean = 0.6 * avg_nn + 0.4 * gp_pred\n",
    "        comb_std = 0.6 * std_nn + 0.4 * gp_std\n",
    "        \n",
    "        # Exploration parameter\n",
    "        kappa = 1.96\n",
    "        ucb = comb_mean + kappa * comb_std\n",
    "        \n",
    "        # Repulsion Penalty\n",
    "        dist_sq = np.sum((x_reshaped - x_start_scaled)**2)\n",
    "        penalty = 10.0 * np.exp(-dist_sq / (2 * 0.1**2))\n",
    "        \n",
    "        return -ucb + penalty\n",
    "\n",
    "    # 5. Trust Region Optimization\n",
    "    radius = 0.2\n",
    "    bounds_scaled = []\n",
    "    for i in range(X_train.shape[1]):\n",
    "        mean, scale = scaler_x.mean_[i], scaler_x.scale_[i]\n",
    "        curr_val = x_start_original[i]\n",
    "        lower = (max(0.0, curr_val - radius) - mean) / scale\n",
    "        upper = (min(1.0, curr_val + radius) - mean) / scale\n",
    "        bounds_scaled.append((lower, upper))\n",
    "    \n",
    "    # Perturbed start\n",
    "    x_init = x_start_scaled + np.random.uniform(-0.1, 0.1, size=x_start_scaled.shape)\n",
    "    \n",
    "    res = minimize(fun=objective_function, x0=x_init, method='L-BFGS-B', \n",
    "                   bounds=bounds_scaled, options={'maxiter': 100})\n",
    "    \n",
    "    return np.clip(scaler_x.inverse_transform(res.x.reshape(1, -1)).flatten(), 0.0, 1.0)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T15:08:43.704058Z",
     "start_time": "2026-02-12T15:08:34.456040Z"
    }
   },
   "source": [
    "submission_queries = {}\n",
    "print(f\"{'Func':<5} | {'Optimizing...'}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "for func_id in range(1, 9):\n",
    "    # Ensure you have updated data to 18 points (10+8) before running\n",
    "    X_known, y_known = load_data(func_id)\n",
    "    next_x = suggest_next_point_scaled(func_id, X_known, y_known)\n",
    "    submission_queries[func_id] = next_x\n",
    "\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"FORMATTED SUBMISSION OUTPUT\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "for func_id, x_val in submission_queries.items():\n",
    "    formatted_str = \"-\".join([f\"{val:.6f}\" for val in x_val])\n",
    "    print(f\"function_number: {func_id}: {formatted_str}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "FORMATTED SUBMISSION OUTPUT\n",
      "==============================\n",
      "function_number: 1: 0.531024-0.533000\n",
      "function_number: 2: 0.868886-1.000000\n",
      "function_number: 3: 0.342138-0.774352-0.617345\n",
      "function_number: 4: 0.220631-0.401128-0.452145-0.431712\n",
      "function_number: 5: 1.000000-0.892988-1.000000-1.000000\n",
      "function_number: 6: 0.288748-0.378009-0.608719-0.969796-0.152636\n",
      "function_number: 7: 0.000000-0.243627-0.458460-0.050169-0.156875-0.888096\n",
      "function_number: 8: 0.000000-0.000000-0.000000-0.013207-0.274043-0.202089-0.000000-0.467955\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
